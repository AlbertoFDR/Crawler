# Crawler ![CI](https://github.com/AlbertoFDR/Crawler/workflows/CI/badge.svg)

Crawler is a web crawler developed in NodeJS which navigate webs collecting the most important aspects. The purpose of this project is to be a crawler template for different types of objectives. 

## Demo

![Demo](name-of-giphy.gif)

### Table of content

- [Crawler Most Important Features](#crawler-most-important-features)
    - [Profiler](#despliegue-de-una-m치quina-virtual)
    - [Files](#configuraci칩n-del-entorno)
    - [WebSockets](#configuraci칩n-del-entorno)
    - [Headers](#configuraci칩n-del-entorno)
- [Usage](#inicio-del-ejercicio)
    - [SEI CERT Java Rules](#sei-cert-java-rules)
- [Example Webs Usage](#inicio-del-ejercicio)
- [FAQ](#inicio-del-ejercicio)
- [Authors](#authors)



## Crawler Most Important Features
### Profiler 
### Profiler 



## Usage


## Example Webs Usage
python3 -m http.server 


WebSockets 
    - pip3 install websockets
    - sudo ./script.sh (Launches the static with the index and the python with the server that receives ws)


## FAQ

## Authors


